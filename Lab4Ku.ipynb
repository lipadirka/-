{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31b8457-d520-44fd-9e8a-6ac6f0ba5635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concerning the proposed newsgroup split, I personally am not in favor of\n",
      "   doing this.  I learn an awful lot about all aspects of graphics by reading\n",
      "   this group, from code to hardware to algorithms.  I just think making 5\n",
      "   different groups out of this is a wate, and will only result in a few posts\n",
      "   a week per group.  I kind of like the convenience of having one big forum\n",
      "   for discussing all aspects of graphics.  Anyone else feel this way?\n",
      "   Just curious.\n",
      "\n",
      "I disagree.  You could learn the same amount by reading all the\n",
      "split groups, and it would make things easier for those of us\n",
      "who are less omnivorous.  There is no \"waste\" in creating news\n",
      "groups -- its just a bit of shuffling about.  I have no problem\n",
      "with only a few posts per week per group - I spend too much time\n",
      "on this as it is.\n",
      "\n",
      "Yep, you can use any type of UNIX, or maybe VMS, or buy a MAC or something...\n",
      "  If you want longer filenames for your documents, I heard of a wordprocessor for\n",
      "windows which let you assign long names to files. Those long filenames could only be\n",
      "seen from that programs open/save dialogs though... Maybe someone knows more about\n",
      "this wordprocessor than I do?\n",
      "            \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rewaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i final got a 24 bit viewer for my povray gener .tga file . it wa written in c by sean malloy and he kindli sent me a copi . he wrote it for the same purpos , to view .tga file use hi speedstar 24 . it onli work with the speedstar 24 and i can not send copi sinc it is not my program . i believ the author may releas a version at a futur time when the program is more develop . he may or may not comment on thi , as he pleas . thank to all who were help . regard ,\n"
     ]
    }
   ],
   "source": [
    "# Лабораторная работа 3\n",
    "# Вариант 1\n",
    "# Используемые методы (KNN,RF,LR)\n",
    "# Подключение библиотек \n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Выбор классов\n",
    "categories = ['comp.graphics', 'comp.os.ms-windows.misc', 'rec.autos']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=35, categories=categories, remove=remove)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=35, categories=categories, remove=remove)\n",
    "print(twenty_train.data[3])\n",
    "print(twenty_test.data[3])\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Применить стемминг\n",
    "def stemn(data):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    stem = []\n",
    "    for text in data:\n",
    "        nltk_tokens = word_tokenize(text)\n",
    "        line = ''.join([' ' + porter_stemmer.stem(word) for word in nltk_tokens])\n",
    "        stem.append(line)\n",
    "    return stem\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "stem_train = []\n",
    "for text in twenty_train.data:\n",
    "    nltk_tokens = word_tokenize(text)\n",
    "    line = ''\n",
    "    for word in nltk_tokens:\n",
    "        line += ' ' + porter_stemmer.stem(word)\n",
    "    stem_train.append(line)\n",
    "print(stem_train[0])\n",
    "\n",
    "stem_test = stemn(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccfdd4-d894-4268-8f1a-2f829f874d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимизация параметров для KNeighborsClassifier\n",
      "Лучшие параметры с использованием стемминга: {'clf__n_neighbors': 5, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Точность с использованием стемминга: 0.5131467345207803\n",
      "Точность с использованием стемминга: 0.5676424720913685\n",
      "Полнота с использованием стемминга: 0.5131467345207803\n",
      "F1-мера с использованием стемминга: 0.5019390442761362\n",
      "Лучшие параметры без стемминга: {'clf__n_neighbors': 5, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Точность без стемминга: 0.47837150127226463\n",
      "Точность без стемминга: 0.5142921279053392\n",
      "Полнота без стемминга: 0.47837150127226463\n",
      "F1-мера без стемминга: 0.4701362633442179\n",
      "\n",
      "\n",
      "Оптимизация параметров для RandomForestClassifier\n",
      "Лучшие параметры с использованием стемминга: {'clf__n_estimators': 200, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Точность с использованием стемминга: 0.8125530110262935\n",
      "Точность с использованием стемминга: 0.8170167261958017\n",
      "Полнота с использованием стемминга: 0.8125530110262935\n",
      "F1-мера с использованием стемминга: 0.8102399764430948\n",
      "Лучшие параметры без стемминга: {'clf__n_estimators': 200, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Точность без стемминга: 0.818490245971162\n",
      "Точность без стемминга: 0.8248192181601309\n",
      "Полнота без стемминга: 0.818490245971162\n",
      "F1-мера без стемминга: 0.8166716958601928\n",
      "\n",
      "\n",
      "Оптимизация параметров для LogisticRegression\n",
      "Лучшие параметры с использованием стемминга: {'clf__C': 0.1, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n",
      "Точность с использованием стемминга: 0.8210347752332485\n",
      "Точность с использованием стемминга: 0.8234307425514724\n",
      "Полнота с использованием стемминга: 0.8210347752332485\n",
      "F1-мера с использованием стемминга: 0.8188652867787675\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = stem_train, stem_test, twenty_train.target, twenty_test.target\n",
    "\n",
    "# Пайплайн для KNN\n",
    "knn_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Параметры для KNN\n",
    "knn_param_grid = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'clf__n_neighbors': [3, 5, 7]}\n",
    "\n",
    "# Пайплайн для RF\n",
    "rf_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Параметры для RF\n",
    "rf_param_grid = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                 'tfidf__use_idf': (True, False),\n",
    "                 'clf__n_estimators': [50, 100, 200]}\n",
    "\n",
    "\n",
    "# Параметры для LR\n",
    "lr_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('scaler', StandardScaler(with_mean=False)), \n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Параметры для  LR\n",
    "lr_param_grid = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                 'tfidf__use_idf': (True, False),\n",
    "                 'clf__C': [0.1, 1, 10]}\n",
    "\n",
    "# Список параметров\n",
    "pipelines = [knn_pipeline, rf_pipeline, lr_pipeline]\n",
    "param_grids = [knn_param_grid, rf_param_grid, lr_param_grid]\n",
    "\n",
    "# Цикл обучения\n",
    "for i, pipeline in enumerate(pipelines):\n",
    "    print(f\"Оптимизация параметров для {pipeline.named_steps['clf'].__class__.__name__}\")\n",
    "    \n",
    "    # Данные со стеммингом\n",
    "    grid_search_stem = GridSearchCV(pipeline, param_grids[i], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_stem.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Лучшие параметры с использованием стемминга:\", grid_search_stem.best_params_)\n",
    "    y_pred_stem = grid_search_stem.predict(X_test)\n",
    "    print(\"Точность с использованием стемминга:\", accuracy_score(y_test, y_pred_stem))\n",
    "    print(\"Точность с использованием стемминга:\", precision_score(y_test, y_pred_stem, average='weighted'))\n",
    "    print(\"Полнота с использованием стемминга:\", recall_score(y_test, y_pred_stem, average='weighted'))\n",
    "    print(\"F1-мера с использованием стемминга:\", f1_score(y_test, y_pred_stem, average='weighted'))\n",
    "\n",
    "    # Данные без стемминга\n",
    "    grid_search_no_stem = GridSearchCV(pipeline, param_grids[i], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_no_stem.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "    print(\"Лучшие параметры без стемминга:\", grid_search_no_stem.best_params_)\n",
    "    y_pred_no_stem = grid_search_no_stem.predict(twenty_test.data)\n",
    "    print(\"Точность без стемминга:\", accuracy_score(twenty_test.target, y_pred_no_stem))\n",
    "    print(\"Точность без стемминга:\", precision_score(twenty_test.target, y_pred_no_stem, average='weighted'))\n",
    "    print(\"Полнота без стемминга:\", recall_score(twenty_test.target, y_pred_no_stem, average='weighted'))\n",
    "    print(\"F1-мера без стемминга:\", f1_score(twenty_test.target, y_pred_no_stem, average='weighted'))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17831b54-7e49-4b66-8da5-28072e3d9838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
